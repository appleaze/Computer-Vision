{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10353915,"sourceType":"datasetVersion","datasetId":6411786}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.models import resnet50\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:38.410562Z","iopub.execute_input":"2025-01-03T15:14:38.410854Z","iopub.status.idle":"2025-01-03T15:14:42.887910Z","shell.execute_reply.started":"2025-01-03T15:14:38.410832Z","shell.execute_reply":"2025-01-03T15:14:42.887046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ANC_PATH = '/kaggle/input/lfw-positive-negative/content/data/anchor/face'\nPOS_PATH = '/kaggle/input/lfw-positive-negative/content/data/positive/face'\nNEG_PATH = '/kaggle/input/lfw-positive-negative/content/data/negative/face'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:42.889352Z","iopub.execute_input":"2025-01-03T15:14:42.889812Z","iopub.status.idle":"2025-01-03T15:14:42.893734Z","shell.execute_reply.started":"2025-01-03T15:14:42.889778Z","shell.execute_reply":"2025-01-03T15:14:42.892825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"anchor_files = [os.path.join(ANC_PATH, f) for f in os.listdir(ANC_PATH) if f.endswith('.jpg')]\npositive_files = [os.path.join(POS_PATH, f) for f in os.listdir(POS_PATH) if f.endswith('.jpg')]\nnegative_files = [os.path.join(NEG_PATH, f) for f in os.listdir(NEG_PATH) if f.endswith('.jpg')]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:42.894801Z","iopub.execute_input":"2025-01-03T15:14:42.895099Z","iopub.status.idle":"2025-01-03T15:14:44.819213Z","shell.execute_reply.started":"2025-01-03T15:14:42.895078Z","shell.execute_reply":"2025-01-03T15:14:44.818210Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"anchor_files = anchor_files[:3000]\npositive_files = positive_files[:3000]\nnegative_files = negative_files[:3000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:44.820439Z","iopub.execute_input":"2025-01-03T15:14:44.820754Z","iopub.status.idle":"2025-01-03T15:14:44.824909Z","shell.execute_reply.started":"2025-01-03T15:14:44.820730Z","shell.execute_reply":"2025-01-03T15:14:44.824109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:45.967350Z","iopub.execute_input":"2025-01-03T15:14:45.967637Z","iopub.status.idle":"2025-01-03T15:14:45.971692Z","shell.execute_reply.started":"2025-01-03T15:14:45.967616Z","shell.execute_reply":"2025-01-03T15:14:45.970718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(file_path):\n    img = Image.open(file_path).convert(\"RGB\")\n    return transform(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:47.728276Z","iopub.execute_input":"2025-01-03T15:14:47.728588Z","iopub.status.idle":"2025-01-03T15:14:47.732321Z","shell.execute_reply.started":"2025-01-03T15:14:47.728566Z","shell.execute_reply":"2025-01-03T15:14:47.731477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = preprocess('/kaggle/input/lfw-positive-negative/content/data/anchor/face/13eaa162-ba39-11ef-b1cd-0242ac1c000c.jpg')\nplt.imshow(img.permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C) for visualization\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:49.605995Z","iopub.execute_input":"2025-01-03T15:14:49.606357Z","iopub.status.idle":"2025-01-03T15:14:49.862311Z","shell.execute_reply.started":"2025-01-03T15:14:49.606327Z","shell.execute_reply":"2025-01-03T15:14:49.861035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SiameseDataset(Dataset):\n    def __init__(self, anchor_files, positive_files, negative_files):\n        self.anchor_files = anchor_files\n        self.positive_files = positive_files\n        self.negative_files = negative_files\n        self.labels = torch.cat([\n            torch.ones(len(anchor_files)),\n            torch.zeros(len(anchor_files))\n        ])\n\n    def __len__(self):\n        return len(self.anchor_files) * 2\n\n    def __getitem__(self, idx):\n        if idx < len(self.anchor_files):\n            anchor_img = preprocess(self.anchor_files[idx])\n            pos_img = preprocess(self.positive_files[idx])\n            label = 1  # Positive pair\n        else:\n            idx = idx - len(self.anchor_files)\n            anchor_img = preprocess(self.anchor_files[idx])\n            neg_img = preprocess(self.negative_files[idx])\n            label = 0  # Negative pair\n        \n        return anchor_img, pos_img if label == 1 else neg_img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:52.724605Z","iopub.execute_input":"2025-01-03T15:14:52.724903Z","iopub.status.idle":"2025-01-03T15:14:52.730867Z","shell.execute_reply.started":"2025-01-03T15:14:52.724880Z","shell.execute_reply":"2025-01-03T15:14:52.729857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = SiameseDataset(anchor_files, positive_files, negative_files)\ndataloader = DataLoader(dataset, shuffle=True, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:54.110030Z","iopub.execute_input":"2025-01-03T15:14:54.110342Z","iopub.status.idle":"2025-01-03T15:14:54.123203Z","shell.execute_reply.started":"2025-01-03T15:14:54.110318Z","shell.execute_reply":"2025-01-03T15:14:54.122427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for anchor, pair_img, label in dataloader:\n    print(anchor.shape, pair_img.shape, label.shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T11:25:24.767547Z","iopub.execute_input":"2025-01-03T11:25:24.767762Z","iopub.status.idle":"2025-01-03T11:25:25.211485Z","shell.execute_reply.started":"2025-01-03T11:25:24.767743Z","shell.execute_reply":"2025-01-03T11:25:25.210641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_anchor, sample_pair_img, sample_label = dataset[0]\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.imshow(sample_anchor.permute(1, 2, 0))\nplt.title(\"Anchor\")\nplt.axis('off')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:56.427075Z","iopub.execute_input":"2025-01-03T15:14:56.427429Z","iopub.status.idle":"2025-01-03T15:14:56.665342Z","shell.execute_reply.started":"2025-01-03T15:14:56.427400Z","shell.execute_reply":"2025-01-03T15:14:56.664460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.subplot(1, 2, 2)\nplt.imshow(sample_pair_img.permute(1, 2, 0))\nplt.title(\"Positive\" if sample_label == 1 else \"Negative\")\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:14:59.438751Z","iopub.execute_input":"2025-01-03T15:14:59.439035Z","iopub.status.idle":"2025-01-03T15:14:59.610422Z","shell.execute_reply.started":"2025-01-03T15:14:59.439012Z","shell.execute_reply":"2025-01-03T15:14:59.609540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = int(0.7 * len(dataset))\nval_size = int(0.15 * len(dataset))\ntest_size = len(dataset) - train_size - val_size  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:15:01.878998Z","iopub.execute_input":"2025-01-03T15:15:01.879344Z","iopub.status.idle":"2025-01-03T15:15:01.883737Z","shell.execute_reply.started":"2025-01-03T15:15:01.879318Z","shell.execute_reply":"2025-01-03T15:15:01.882750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:15:03.949623Z","iopub.execute_input":"2025-01-03T15:15:03.949957Z","iopub.status.idle":"2025-01-03T15:15:03.959270Z","shell.execute_reply.started":"2025-01-03T15:15:03.949931Z","shell.execute_reply":"2025-01-03T15:15:03.958352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:15:05.598970Z","iopub.execute_input":"2025-01-03T15:15:05.599299Z","iopub.status.idle":"2025-01-03T15:15:05.603472Z","shell.execute_reply.started":"2025-01-03T15:15:05.599274Z","shell.execute_reply":"2025-01-03T15:15:05.602590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class VGGFaceEmbedding(nn.Module):\n    def __init__(self):\n        super(VGGFaceEmbedding, self).__init__()\n        self.meta = {\n            'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n            'std': [1, 1, 1],\n            'imageSize': [224, 224, 3]\n        }\n        # Load pre-trained ResNet-50\n        self.base_model = resnet50(pretrained=True)\n        # Remove the final fully connected layer\n        self.base_model = nn.Sequential(*list(self.base_model.children())[:-2])\n        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n        self.flatten = nn.Flatten()\n\n    def forward(self, x):\n        x = self.base_model(x)\n        x = self.pooling(x)\n        x = self.flatten(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:15:08.453566Z","iopub.execute_input":"2025-01-03T15:15:08.453854Z","iopub.status.idle":"2025-01-03T15:15:08.459684Z","shell.execute_reply.started":"2025-01-03T15:15:08.453832Z","shell.execute_reply":"2025-01-03T15:15:08.458636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class L1Dist(nn.Module):\n    def __init__(self):\n        super(L1Dist, self).__init__()\n\n    def forward(self, input_embedding, validation_embedding):\n        return torch.abs(input_embedding - validation_embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:15:10.907823Z","iopub.execute_input":"2025-01-03T15:15:10.908101Z","iopub.status.idle":"2025-01-03T15:15:10.912424Z","shell.execute_reply.started":"2025-01-03T15:15:10.908080Z","shell.execute_reply":"2025-01-03T15:15:10.911380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_siamese_model():\n    class SiameseNetwork(nn.Module):\n        def __init__(self):\n            super(SiameseNetwork, self).__init__()\n            self.embedding = VGGFaceEmbedding()\n            self.distance = L1Dist()\n            self.fc1 = nn.Linear(2048, 512)  # Assuming embedding output size is 2048\n            self.fc2 = nn.Linear(512, 1)\n            self.sigmoid = nn.Sigmoid()\n\n        def forward(self, input_image, validation_image):\n            input_embedding = self.embedding(input_image)\n            validation_embedding = self.embedding(validation_image)\n            distances = self.distance(input_embedding, validation_embedding)\n            x = self.fc1(distances)\n            x = self.fc2(x)\n            x = self.sigmoid(x)\n            return x\n\n    return SiameseNetwork()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:15:12.949766Z","iopub.execute_input":"2025-01-03T15:15:12.950072Z","iopub.status.idle":"2025-01-03T15:15:12.955131Z","shell.execute_reply.started":"2025-01-03T15:15:12.950046Z","shell.execute_reply":"2025-01-03T15:15:12.954365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"siamese_model = make_siamese_model()\nprint(siamese_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:15:14.760073Z","iopub.execute_input":"2025-01-03T15:15:14.760424Z","iopub.status.idle":"2025-01-03T15:15:15.817276Z","shell.execute_reply.started":"2025-01-03T15:15:14.760395Z","shell.execute_reply":"2025-01-03T15:15:15.816394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"binary_cross_entropy_loss = nn.BCELoss()\noptimizer = optim.Adam(siamese_model.parameters(), lr=1e-4)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef train_step(batch, model, loss_fn, optimizer):\n    model.train()\n    input_image, validation_image, labels = batch\n    # Move to device and convert labels to float\n    input_image = input_image.to(device)\n    validation_image = validation_image.to(device)\n    labels = labels.float().to(device)\n    \n    # Forward pass\n    predictions = model(input_image, validation_image).squeeze()\n    loss = loss_fn(predictions, labels)\n    \n    # Backward pass\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\ndef validate(data_loader, model, loss_fn):\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in data_loader:\n            input_image, validation_image, labels = batch\n            # Move to device and convert labels to float\n            input_image = input_image.to(device)\n            validation_image = validation_image.to(device)\n            labels = labels.float().to(device)\n            \n            predictions = model(input_image, validation_image).squeeze()\n            loss = loss_fn(predictions, labels)\n            val_loss += loss.item()\n            predicted = (predictions > 0.5).float()\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n    accuracy = correct / total\n    return val_loss / len(data_loader), accuracy\n\ndef train(data_loader, val_loader, model, loss_fn, optimizer, epochs, patience=5):\n    try:\n        print(f\"Training on {device}\")\n        model = model.to(device)\n        \n        train_losses = []\n        val_losses = []\n        val_accuracies = []\n        \n        best_val_loss = float('inf')\n        epochs_no_improve = 0\n        early_stop = False\n        \n        for epoch in range(epochs):\n            if early_stop:\n                print(\"Early stopping triggered.\")\n                break\n                \n            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n            epoch_loss = 0.0\n            model.train()\n            \n            for batch_idx, batch in enumerate(data_loader):\n                loss = train_step(batch, model, loss_fn, optimizer)\n                epoch_loss += loss\n                if (batch_idx + 1) % 10 == 0:\n                    print(f\"Batch {batch_idx + 1}/{len(data_loader)}, Loss: {loss:.4f}\")\n            \n            train_loss = epoch_loss / len(data_loader)\n            val_loss, val_accuracy = validate(val_loader, model, loss_fn)\n            \n            train_losses.append(train_loss)\n            val_losses.append(val_loss)\n            val_accuracies.append(val_accuracy)\n            \n            print(f\"Epoch {epoch + 1} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n            \n            # Early stopping logic\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                epochs_no_improve = 0\n                # Optionally, save the best model\n                torch.save(model.state_dict(), 'best_model.pth')\n            else:\n                epochs_no_improve += 1\n                if epochs_no_improve >= patience:\n                    early_stop = True\n        \n        # Plot metrics\n        plt.figure(figsize=(12, 4))\n        \n        plt.subplot(1, 2, 1)\n        plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n        plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.title(\"Loss vs Epochs\")\n        \n        plt.subplot(1, 2, 2)\n        plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label=\"Validation Accuracy\")\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        plt.title(\"Validation Accuracy vs Epochs\")\n        plt.show()\n        \n        return train_losses, val_losses, val_accuracies\n        \n    except Exception as e:\n        print(f\"Error during training: {str(e)}\")\n        # Ensure we still return the lists even if training fails partway through\n        return train_losses, val_losses, val_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:18:07.220925Z","iopub.execute_input":"2025-01-03T15:18:07.221284Z","iopub.status.idle":"2025-01-03T15:18:07.235377Z","shell.execute_reply.started":"2025-01-03T15:18:07.221254Z","shell.execute_reply":"2025-01-03T15:18:07.234467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 20\ntrain_losses, val_losses, val_accuracies = train(\n    train_loader, \n    val_loader, \n    siamese_model, \n    binary_cross_entropy_loss, \n    optimizer, \n    EPOCHS,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:18:11.148568Z","iopub.execute_input":"2025-01-03T15:18:11.148859Z","iopub.status.idle":"2025-01-03T15:29:29.050918Z","shell.execute_reply.started":"2025-01-03T15:18:11.148837Z","shell.execute_reply":"2025-01-03T15:29:29.049988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_cpu = siamese_model.to(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:34:28.069865Z","iopub.execute_input":"2025-01-03T15:34:28.070293Z","iopub.status.idle":"2025-01-03T15:34:28.181957Z","shell.execute_reply.started":"2025-01-03T15:34:28.070256Z","shell.execute_reply":"2025-01-03T15:34:28.180954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model_cpu.state_dict(), \"model_cpu.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T15:34:54.586487Z","iopub.execute_input":"2025-01-03T15:34:54.586812Z","iopub.status.idle":"2025-01-03T15:34:54.707450Z","shell.execute_reply.started":"2025-01-03T15:34:54.586784Z","shell.execute_reply":"2025-01-03T15:34:54.706524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(siamese_model.state_dict(), 'siamese_model_weights.pth')\nprint(\"Model state_dict saved to siamese_model_weights.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T11:33:42.751985Z","iopub.execute_input":"2025-01-03T11:33:42.752316Z","iopub.status.idle":"2025-01-03T11:33:42.915642Z","shell.execute_reply.started":"2025-01-03T11:33:42.752293Z","shell.execute_reply":"2025-01-03T11:33:42.914721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"siamese_model.load_state_dict(torch.load('siamese_model_weights.pth'))\nsiamese_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T11:33:42.918302Z","iopub.execute_input":"2025-01-03T11:33:42.918544Z","iopub.status.idle":"2025-01-03T11:33:43.028301Z","shell.execute_reply.started":"2025-01-03T11:33:42.918522Z","shell.execute_reply":"2025-01-03T11:33:43.027405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\nall_y_true = []\nall_y_pred = []\nall_y_prob = []  # Store probabilities for ROC-AUC\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nsiamese_model.to(device)\n\nsiamese_model.eval()  # Set model to evaluation mode\nwith torch.no_grad():\n    for anchor_img, paired_img, y_true in test_loader:\n        anchor_img = anchor_img.to(device)\n        paired_img = paired_img.to(device)\n        y_true = y_true.to(device)\n\n        y_hat = siamese_model(anchor_img, paired_img)\n        y_prob = torch.sigmoid(y_hat).squeeze().cpu().numpy()  # Probabilities\n        y_pred = [1.0 if prob > 0.5 else 0.0 for prob in y_prob]  # Binary predictions\n\n        all_y_true.extend(y_true.cpu().numpy())\n        all_y_pred.extend(y_pred)\n        all_y_prob.extend(y_prob)\n\n# Print predictions and true labels\nprint(\"Predictions:\", all_y_pred)\nprint(\"True Labels:\", all_y_true)\n\n# Calculate metrics\naccuracy = accuracy_score(all_y_true, all_y_pred)\nprecision = precision_score(all_y_true, all_y_pred)\nrecall = recall_score(all_y_true, all_y_pred)\nf1 = f1_score(all_y_true, all_y_pred)\nroc_auc = roc_auc_score(all_y_true, all_y_prob)\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"ROC-AUC: {roc_auc:.4f}\")\n\n# Check class distribution\nimport numpy as np\nprint(\"Class Distribution:\", np.unique(all_y_true, return_counts=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T11:33:43.029153Z","iopub.execute_input":"2025-01-03T11:33:43.029463Z","iopub.status.idle":"2025-01-03T11:33:53.415749Z","shell.execute_reply.started":"2025-01-03T11:33:43.029427Z","shell.execute_reply":"2025-01-03T11:33:53.415001Z"}},"outputs":[],"execution_count":null}]}